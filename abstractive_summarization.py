# -*- coding: utf-8 -*-
"""Abstractive Summarization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HhvHc-mCtYIQAJfgk6sbSFCVKqk2ysQL
"""

!pip install transformers sentencepiece rouge-score pandas openpyxl

import pandas as pd
import numpy as np
from transformers import PegasusTokenizer, PegasusForConditionalGeneration
from rouge_score import rouge_scorer
import torch

# Load model and tokenizer (legal fine-tuned Pegasus from Hugging Face)
model_name = "nsi319/legal-pegasus"  # Pegasus fine-tuned on legal data
tokenizer = PegasusTokenizer.from_pretrained(model_name)
model = PegasusForConditionalGeneration.from_pretrained(model_name)

# Check if GPU is available
device = "cuda" if torch.cuda.is_available() else "cpu"
model = model.to(device)

# Load data
test_df = pd.read_excel("test_data.xlsx")
texts = test_df["Text"].tolist()
references = test_df["Summary"].tolist()

# Summarization function
def generate_summary(text, max_length=128, min_length=30):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding="longest", max_length=512).to(device)
    summary_ids = model.generate(inputs["input_ids"], max_length=max_length, min_length=min_length, length_penalty=1.0, num_beams=4, early_stopping=True)
    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)

# Generate summaries
generated_summaries = [generate_summary(text) for text in texts]

# Evaluate with ROUGE
scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)
rouge_scores = {"rouge1": [], "rouge2": [], "rougeL": []}

for ref, gen in zip(references, generated_summaries):
    score = scorer.score(ref, gen)
    for key in rouge_scores:
        rouge_scores[key].append(score[key].fmeasure)

# Calculate average scores
average_scores = {key: np.mean(vals) for key, vals in rouge_scores.items()}

# Print results
print("Legal-Pegasus ROUGE Scores:")
for key, val in average_scores.items():
    print(f"{key}: {val:.4f}")